{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CheckYoSelf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelCondo/Team9-APS360-Project/blob/main/CheckYoSelf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnxz_RI3s_LQ"
      },
      "source": [
        "# Check Yo' Self \n",
        "**Self-serve checkout enhancement using Neural Networks and Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGq6kr8QkR8L"
      },
      "source": [
        "## Architecture\n",
        "![alt text](https://github.com/MichaelCondo/Team9-APS360-Project/blob/main/docs/Architecture_Diagram.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtKWWS4Zs19j"
      },
      "source": [
        "#### Colab Link\n",
        "https://colab.research.google.com/github/MichaelCondo/Team9-APS360-Project/blob/main/CheckYoSelf.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4BPDZRqtYCb"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkwqShLNjs_D"
      },
      "source": [
        "## 0. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6T1wQpnjykA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgBq2ZRCiIBr"
      },
      "source": [
        "## 1. Data Collection\n",
        "\n",
        "**Tasks**:\n",
        "* Understand Fruits 360 dataset\n",
        "* Loading dataset into Colab\n",
        "* Collecting prices of fruits\n",
        "* Splitting the dataset into training, validation and testing (stratify or random) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec_eenN_vloX"
      },
      "source": [
        "## 1.1 Fruits 360 Dataset\n",
        "\n",
        "[Fruits 360](https://www.kaggle.com/moltean/fruits) is a dataset of 90000+ images of 130+ fruits and vegetables, in RGB colour at 100x100px a piece.\n",
        "\n",
        "We're using [the GitHub mirror](https://github.com/Horea94/Fruit-Images-Dataset) to download the dataset as it does not require authentication to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVphS1bhiNmF",
        "outputId": "29a26eef-f8e5-4703-8fa4-0e56aa121ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the dataset from GitHub\n",
        "!wget -nc https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip \\\n",
        "    && mkdir -p \"/root/project\" \\\n",
        "    && unzip -n \"master.zip\" -d \"/root/project/datasets\" \\\n",
        "    && find \"/root/project/datasets/\" -mindepth 2 -maxdepth 2 -type d -ls\n",
        "DATA_MASTER_PATH = \"/root/project/datasets/Fruit-Images-Dataset-master\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘master.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  master.zip\n",
            "9ce036635e3d9608985231c6579870ecc482a5b2\n",
            "  5416381      4 drwxr-xr-x   2 root     root         4096 Nov  5 18:34 /root/project/datasets/Fruit-Images-Dataset-master/test-multiple_fruits\n",
            "  5374025      4 drwxr-xr-x 133 root     root         4096 Sep  9 15:32 /root/project/datasets/Fruit-Images-Dataset-master/Test\n",
            "  5396845      4 drwxr-xr-x 133 root     root         4096 Sep  9 15:32 /root/project/datasets/Fruit-Images-Dataset-master/Training\n",
            "  5416353      4 drwxr-xr-x   2 root     root         4096 Nov  5 18:34 /root/project/datasets/Fruit-Images-Dataset-master/papers\n",
            "  5416356      4 drwxr-xr-x   5 root     root         4096 Sep  9 15:32 /root/project/datasets/Fruit-Images-Dataset-master/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPu4vwrQ1LMs"
      },
      "source": [
        "Let's take a look at the contents of the dataset. \n",
        "\n",
        "How many training samples are there for each of the classes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm81ED0dxA-u",
        "outputId": "d093cf4b-ff29-4a81-9626-ec74c6969a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd \"{DATA_MASTER_PATH}/Training\" \\\n",
        "    && find -maxdepth 2 -mindepth 2 -type f -printf \"%h\\0\" \\\n",
        "    | uniq -zc | tr '\\0' '\\n' | sort -rh  \\\n",
        "    | (sed -u 10q ; echo \"...\" ; tail)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    984 ./Grape Blue\n",
            "    900 ./Plum 3\n",
            "    738 ./Tomato 3\n",
            "    738 ./Tomato 1\n",
            "    738 ./Strawberry Wedge\n",
            "    738 ./Peach 2\n",
            "    738 ./Melon Piel de Sapo\n",
            "    738 ./Cherry Rainier\n",
            "    738 ./Cherry 2\n",
            "    735 ./Walnut\n",
            "...\n",
            "    438 ./Onion White\n",
            "    429 ./Apple Red 3\n",
            "    427 ./Avocado\n",
            "    426 ./Mango Red\n",
            "    420 ./Plum 2\n",
            "    392 ./Cucumber Ripe\n",
            "    367 ./Tomato Maroon\n",
            "    300 ./Pear Kaiser\n",
            "    300 ./Mangostan\n",
            "    297 ./Ginger Root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn02WDLF9DYr"
      },
      "source": [
        "### 1.2: ?\n",
        "\n",
        "tbh i think data processing should go here before we make the data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zUPgKgiOZ1"
      },
      "source": [
        "## 2. Data Processing\n",
        "\n",
        "**Tasks**:\n",
        "* Remove items that are not sold as individual fruits (i.e. vegetables, small berries, bunched bananas)\n",
        "* Consolidate split classes either by combining or removing (e.g. Apple Red 1/2/3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iijoVzilIc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCHzon3ViljJ"
      },
      "source": [
        "## 3. Baseline Model\n",
        "\n",
        "**Tasks**:\n",
        "* Setup and train random forrest model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnj8llP9it8n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E1bdxW8iugn"
      },
      "source": [
        "## 4. Model Setup\n",
        "\n",
        "**Tasks**:\n",
        "* Using previous labs as reference, create CNN skeleton to work for 100x100 RGB images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyL2mbjVjDeH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDwEYmJojEFI"
      },
      "source": [
        "## 5. Model Training and Tuning\n",
        "\n",
        "**Tasks**:\n",
        "* Write training code \n",
        "* Adjust hyperparameters to get at least 90% validation accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qSSxcEQjLVG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}